\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\usepackage[utf8]{vietnam}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}    
\begin{document}

\title{CS116 - RandomForestClassifier\\}

\author{\IEEEauthorblockN{1\textsuperscript{st} Lâm Minh Tuấn}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle





\section{Tổng quan mô hình}

Tương tự như ý tưởng \emph{The Wisdom of Crowds} được đề xuất bởi James Surowiecki vào năm 2004 cho rằng thông tin tổng hợp từ 1 nhóm sẽ tốt hơn 1 cá nhân, RandomForestClassifier là mô hình phân lớp dựa trên cây quyết định, tuy nhiên khác với thuật toán cây quyết định chỉ dùng duy nhất 1 cây để đưa ra dự đoán, Random Forest lại dùng hàng loạt những cây quyết định khác nhau (có yếu tố ngẫu nhiên), sau đó kết quả dự đoán được tổng hợp từ các cây quyết định đó và kết quả cho ra tốt hơn thuật toán Decision Tree chỉ với một cây quyết định đơn lẻ. 

\section{Cài đặt và đánh giá mô hình với thư viện scikit-learn}
\subsection{Giải thích một số tham số quan trọng của mô hình trong thư viện scikit-learn}
Do số lượng tham số của mô hình trong thư viện scikit-learn quá nhiều và một vài tham số thật sự không quan trọng đối với hiệu quả của mô hình nên ta sẽ chỉ xem xét một số tham số quan trọng của mô hình.
\begin{itemize}
\item \emph{max\_features}: số lượng đặc trưng mà mỗi cây trong mô hình sử dụng để tiến hành chia node. Tăng \emph{max\_features} thường cải thiện hiệu quả của mô hình vì ở nút cần tách có nhiều sự lựa chọn hơn để tách. Tuy nhiên điều này làm giảm tính đa dạng của rừng cây vốn là đặc trưng của thuật toán này có thể dẫn đến hiện tượng overfitting, đồng thời tăng tham số này sẽ làm mô hình chạy chậm hơn.
\item \emph{n\_estimators}: số lượng cây sử dụng trong mô hình. Random Forest là thuật toán dựa  trên rừng cây nên theo lý thuyết, số lượng cây càng lớn thì sẽ cho ra đầu ra càng chính xác. Tuy nhiên càng nhiều cây thì thời gian mà mô hình dự đoán càng tăng lên. Qua nhiều thực nghiệm, người ta đã thấy được rằng đến một số lượng cây nhất định nào đó thì độ chính xác không còn tăng lên đáng kể nữa mà ngược lại còn làm tăng thời gian dự đoán của mô hình nên ta cần chọn một số lượng cây thích hợp để vừa có thể tiết kiệm thời gian vừa có thể giúp cho mô hình đưa ra độ chính xác gần tối ưu.
\item \emph{max\_depth}: độ sâu của cây. Sử dụng tham số này ta có thể giới hạn được độ sâu của cây được sử dụng trong thuật toán Random Forest. Khi độ sâu của cây tăng lên, độ chính xác trên tập train sẽ tăng lên nhanh chóng. Mặt khác khi độ sâu của cây tăng lên, độ chính xác trên tập test cũng sẽ tăng lên nhưng khi đến một điểm nào đó thì độ chính xác trên tập test lại bắt đầu giảm nhanh. Đó là do mô hình đã bị overfitting do mô hình đã quá khớp dữ liệu trên tập test. Vì thế ta cũng cần phải kiểm soát tham số này một cách cẩn thận.
\item \emph{min\_samples\_split}: tham số báo cho cây trong mô hình số lượng quan sát tối thiểu cần thiết để tách nút. Giá trị mặc định của mô hình là 2 có nghĩa là nếu một nút trong cây có nhiều hơn 2 quan sát và nút đó chưa phải là nút thuần túy (chỉ chứa giá trị thuộc 1 lớp) thì ta lại tiếp tục chia nút đó thành các nút con. Điều này làm cho cây tiếp tục chia nút cho đến khi các node lá trở nên hoàn toàn thuần túy, do đó có thể dẫn đến mô hình bị overfitting. Ngược lại khi tham số này quá cao thì cây sẽ ít tách các node ra làm cho mô hình bị underfitting.
\item \emph{min\_samples\_leaf}: số lượng mẫu tối thiểu trong node lá. Tương tự như \emph{min\_samples\_split}, tham số này được dùng để kiểm soát tình trạng overfitting. Khi tham số này quá thấp thì mô hình sẽ xảy ra tình trạng overfitting, còn nếu tham số này quá cao thì mô hình sẽ xảy ra tình trạng underfitting.
\item \emph{max\_sample}: số lượng mẫu tối đa đưa vào cây trong rừng để huấn luyện. Thông thường càng nhiều mẫu được đưa vào để cây huấn luyện thì độ chính xác mà mô hình đưa ra càng cao, tuy nhiên do Random Forest là thuật toán dựa trên sự ngẫu nhiên của từng cây nên không cần thiết phải đưa tất cả các mẫu dữ liệu cho cây huấn luyện.
\item \emph{criterion}: độ đo dùng để chia các node trong cây.
\end{itemize}
\subsection{Chia tập train và tập test}
\begin{lstlisting}
from sklearn.model_selection import train_test_split
X_train , X_test , Y_train , Y_test = train_test_split(X,Y, test_size=0.3 , random_state=42)
\end{lstlisting}
Ta tiến hành chia dữ liệu cho tập train và tập test theo tỉ lệ 0.3 (70\% dữ liệu gốc được dùng cho tập train và 30\% dữ liệu gốc được dùng cho tập test).
\subsection{Chuẩn hóa dữ liệu}
Vì đa số các cột đầu vào chỉ bao gồm các giá trị nhị phân (0 và 1) nên ta sẽ không cần chuẩn hóa những đặc trưng đó mà chỉ cần chuẩn hóa những đặc trưng chứa các giá trị khác nhau.
\begin{lstlisting}
needscale = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']
\end{lstlisting}
Trong đó \emph{needscale} chứa các đặc trưng cần được chuẩn hóa.
\begin{lstlisting}
from sklearn.preprocessing import StandardScaler
scalar = StandardScaler()
scalar.fit(X_train[needscale])
X_train[needscale] = scalar.transform(X_train[needscale])
X_test[needscale] = scalar.transform(X_test[needscale])
\end{lstlisting}
Ở bước chuẩn hóa dữ liệu ta sử dụng StandardScaler(). Dữ liệu được chuẩn hóa được tính dựa trên trung bình và độ lệch chuẩn của dữ liệu gốc. Từ đó dữ liệu được chuẩn hóa sẽ có phân phối chuẩn. StandardScaler() giữ lại thông tin của các điểm ngoại lệ làm cho thuật toán ít nhạy cảm hơn với các điểm ngoại lệ đó.
\subsection{Xây dựng mô hình}
\subsubsection{Mô hình mặc định không truyền tham số với dữ liệu đã được chuẩn hóa}
\hfill
\begin{lstlisting}
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train, Y_train)
\end{lstlisting}
Để mô hình cho kết quả tốt hơn, ta có thể kết hợp GridSearchCV kết hợp với kiểm định chéo để tìm ra bộ tham số tốt nhất cho mô hình:
\begin{lstlisting}
param_grid = { 
    'n_estimators': [100, 200, 800],
    'max_depth' : [4, 8, 16, 32, 64],
    'min_samples_leaf' : [1, 20, 40, 60],
    'min_samples_split': [2, 3, 4],
    'criterion' :['gini', 'entropy']
}
\end{lstlisting}
Do thuật toán GridSearchCV dò từng tổ hợp tham số để tìm ra tham số tối ưu nên để tiết kiệm thời gian, ta chỉ tìm những tham số quan trọng tối ưu để tiết kiệm thời gian.
\begin{lstlisting}
from sklearn.model_selection import GridSearchCV
CV_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)
CV_rf.fit(X_train, Y_train)
}
\end{lstlisting}
\subsubsection{Mô hình với tham số tối ưu với dữ liệu đã được chuẩn hóa}
\hfill\\
Tham số tốt nhất cho mô hình mà GridSearchCV tìm được:
\begin{lstlisting}
{'criterion': 'gini',
 'max_depth': 8,
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'n_estimators': 200}
\end{lstlisting}
Áp dụng tham số tối ưu để xây dựng mô hình mới:
\begin{lstlisting}
rf_gs = RandomForestClassifier(max_depth=8, criterion='gini', n_estimators=200, min_samples_split=2, min_samples_leaf=1)
rf_gs.fit(X_train, Y_train)
\end{lstlisting}
\subsection{Đánh giá mô hình}
\subsubsection{Đánh giá mô hình không dùng kiểm định chéo}
\hfill\\
Để đánh giá được tầm quan trọng của việc chuẩn hóa dữ liệu đối với mô hình, ta sẽ tiến hành so sánh mô hình với dữ liệu đầu vào đã được chuẩn hóa và mô hình với dữ liệu đầu vào không được chuẩn hóa.
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{sosanh.png}}
\caption{So sánh 4 mô hình dựa trên Accuracy và F1 Score}
\label{fig}
\end{figure}

Qua quan sát ở hình trên, ta có thể thấy được rằng mô hình với tham số tối ưu đưa ra kết quả tốt hơn một chút so với mô hình mặc định không truyền tham số. Và ta cũng có thể thấy được rằng việc chuẩn hóa dữ liệu đầu vào không giúp cho mô hình có kết quả tốt hơn so với dữ liệu gốc. Để đảm bảo tính khách quan và loại bỏ yếu tố ngẫu nhiên trong quá trình đánh giá mô hình, ta tiếp tục sử dụng kiểm định chéo với 5 Fold để đánh giá mô hình.
\subsubsection{Đánh giá mô hình dùng kiểm định chéo}
\hfill\\
\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{sosanh2.png}}
\caption{So sánh 4 mô hình dựa trên Accuracy và F1 Score với 5 Fold}
\label{fig}
\end{figure}

Với kiểm định chéo, ta thấy được rằng mô hình với tham số tối ưu vẫn đưa ra kết quả chỉ tốt hơn một chút so với mô hình mặc định. Và mô hình với dữ liệu đầu vào đã được chuẩn hóa cũng không đưa ra kết quả tốt hơn so với dữ liệu đầu vào gốc. Như vậy ta có thể kết luận rằng việc chuẩn hóa dữ liệu là không cần thiết đối với mô hình này. Điều này có thể giải thích đơn giản như sau: tương tự như các thuật toán dựa trên cây khác như Gradient Boosting hay Decision Tree, Random Forest không nhạy cảm với độ lớn của các biến, do đó việc chuẩn hóa dữ liệu là không cần thiết đối với các mô hình này. 
\subsection{Ưu và nhược điểm của mô hình}
\begin{itemize}
\item Ưu điểm:
\begin{itemize}
\item Không yêu cầu chuẩn hóa dữ liệu.
\item Thuật toán đơn giản và dễ hiểu.
\item Mô hình cho độ chính xác cao.
\item Ít nhạy cảm với các điểm ngoại lệ.
\item Xử lý tốt dữ liệu có mối quan hệ tuyến tính và phi tuyến tính.
\end{itemize}
\item Nhược điểm:
\begin{itemize}
\item Hạn chế chính của Random Forest là vấn đề thời gian do dựa vào một "rừng cây" để huấn luyện và đưa ra dự đoán, tuy nhiên trong thư viện scikit-learn thì thuật toán này cho tốc độ khá nhanh.
\item Quá nhiều tham số trong mô hình để tinh chỉnh, tiêu tốn rất nhiều thời gian cho các thuật toán tìm tham số tối ưu.
\end{itemize}
\end{itemize}
\subsection{Kết luận}
RandomForestClassifier là một mô hình rất đơn giản và dễ hiểu, tuy nhiên đây là một mô hình cho hiệu quả rất tốt trái ngược hoàn toàn so với sự đơn giản của nó. Nhược điểm chính về thời gian của mô hình này cũng đã được giải quyết khi trong thư viện scikit-learn, mô hình có thời gian huấn luyện khá nhanh. Bằng sự hiệu quả trong việc dự đoán, và không yêu cầu quá nhiều bước tiền xử lý dữ liệu đầu vào, RandomForestClassifier đã chứng minh mình là một trong những mô hình phân lớp tốt nhất còn được sử dụng đến tận ngày nay.
\end{document}
